# Amazon-Sentiment-Analysis
This project performs Sentiment Analysis on Amazon reviews using Natural Language Processing (NLP) and Deep Learning techniques. A LSTM-based model is trained to classify reviews as positive or negative.

ðŸ›  Model Performance

Precision, Recall, F1-Score, and Accuracy:
            precision    recall  f1-score   support

           0       0.95      0.93      0.94    205496
           1       0.93      0.95      0.94    194504

    accuracy                           0.94    400000
   macro avg       0.94      0.94      0.94    400000
weighted avg       0.94      0.94      0.94    400000



ðŸ“Œ Features

    Dataset: The project uses Amazon reviews from train.ft.txt.bz2 and test.ft.txt.bz2 files.

    Data Cleaning: Special characters, numbers, stopwords, and URLs are removed from text.

    Tokenization: Text is converted into numerical form using Keras Tokenizer.

    Model Training: An LSTM model is trained using Adam optimizer and binary_crossentropy loss function.

    Evaluation: The model's performance is analyzed using precision, recall, f1-score, and accuracy.

    User Testing: The model can quickly predict sentiment for given text inputs.



    ðŸ“¦ Amazon-Sentiment-Analysis
 â”£ ðŸ“‚ data
 â”ƒ â”£ ðŸ“„ amazon_reviews_train.csv
 â”ƒ â”£ ðŸ“„ amazon_reviews_test.csv
 â”£ ðŸ“‚ models
 â”ƒ â”£ ðŸ“„ my_model.h5  # Trained model
 â”£ ðŸ“œ sentiment_analysis.py  # Main model script
 â”£ ðŸ“œ requirements.txt  # Dependencies
 â”£ ðŸ“œ README.md  # Project documentation




pip install -r requirements.txt
python sentiment_analysis.py


ðŸš€ Example Usage

The following Python script loads the model and predicts sentiment for a given text:

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import re

model = load_model("models/my_model.h5")

def clean_text(text):
    text = text.lower().strip()
    text = re.sub(r'https?:\/\/\S+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    return text

def predict_sentiment(text, tokenizer, maxlen=100):
    text = clean_text(text)
    sequence = tokenizer.texts_to_sequences([text])
    padded_sequence = pad_sequences(sequence, maxlen=maxlen, padding='post')
    prediction = model.predict(padded_sequence)
    return "Positive" if prediction > 0.5 else "Negative"

tokenizer = ...  # Load or retrain tokenizer

# Test prediction
print(predict_sentiment("This product is amazing!", tokenizer))




ðŸ“Œ Development Stages

âœ… Data cleaning and preprocessing completed.
âœ… LSTM model trained and evaluated.
âœ… Real-time prediction on user input is functional.
ðŸ”œ Model optimization and additional data augmentation can be implemented.
